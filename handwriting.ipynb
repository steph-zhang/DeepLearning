{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented by zmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # 使用了其中的log_softmax函数和nll_loss损失函数\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个字典存放一些常量参数\n",
    "args = {\n",
    "    \"batch_size\": 512, # 训练数据和测试数据的时候每个mini-batch包的大小为512\n",
    "    \"epoch\": 10, # 训练和测试的迭代次数\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 计算设备\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\"./data/\", train=True, download=True,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(), # 将图像转为tensor格式\n",
    "                              transforms.Normalize((0.1307,), (0.3081,)) # 0.1307和0.3081是mnist数据集的均值和标准差，可以将灰度转换到0~1之间\n",
    "                          ])),\n",
    "        batch_size=args[\"batch_size\"],\n",
    "        shuffle=True, # 打乱顺序\n",
    "        drop_last=True #舍弃最后一个大小不足512的batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\"./data/\", train=False, download=True,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,))\n",
    "                          ])),\n",
    "        batch_size=args[\"batch_size\"],\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建卷积神经网络\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__();\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),  # 卷积层: (in_channel, out_channel, kernel_size)\n",
    "            nn.ReLU(inplace=True),  # 激活层 ReLU\n",
    "            nn.MaxPool2d(2, 2),  # 最大池化\n",
    "            nn.Conv2d(10, 20, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),  # 拉平成向量\n",
    "            nn.Linear(500, 256),  # 全连接层\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 10)\n",
    "        ) # 原来的图像经过loader和net之后输出一个1x10的向量\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.net(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型和优化器\n",
    "model = Net().to(args[\"device\"]) # 转到GPU上进行计算\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(model, device, optimizer, train_loader, epoch):\n",
    "    model.train() # 将模块设置为训练模式,作用未知\n",
    "    # batch_idx:mini_batch的编号， enumerate除了返回train_loader的x,y数据之外，还返回一个从0开始自动迭代的编号\n",
    "    for batch_idx, (x_data, y_data) in  enumerate(train_loader):\n",
    "        x_data, y_data = x_data.to(device), y_data.to(device) # 把数据移到GPU上\n",
    "        # ①前馈 ②计算损失 ③反向传播，更新梯度（每次更新梯度前要清零）\n",
    "        y_hat = model(x_data)\n",
    "        loss = F.nll_loss(y_hat, y_data)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 一共需要60000/512=117个周期，所以我们每29个周期观察一次\n",
    "        if(batch_idx + 1) % 29 == 0:\n",
    "            print(\"TrainEpoch:{} Progress:({}/{} ({:.4f}%)\\tloss:{:.6f}\".format(\n",
    "                epoch, \n",
    "                args[\"batch_size\"] * batch_idx, # 已经训练的数据个数\n",
    "                len(train_loader.dataset), # 需要训练的数据个数\n",
    "                100 * args[\"batch_size\"] * batch_idx / len(train_loader.dataset), # 进度\n",
    "                loss.item() \n",
    "            ))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试函数\n",
    "def test(model, device, test_loader):\n",
    "    model.eval() # 将模块设置为评估模式,作用未知\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for x_data, y_data in test_loader:\n",
    "        x_data, y_data = x_data.to(device), y_data.to(device) # 把数据移到GPU上\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x_data)\n",
    "            loss += F.nll_loss(y_hat, y_data)\n",
    "            y_hat = y_hat.max(1, keepdim=True)[1]\n",
    "            # y_hat的形状是512*10的tensor，第一个参数1表示按行取最大值（0是按列），[1]是取最大值的下标（[0]是最大值），也就是识别结果\n",
    "            correct += y_hat.eq(y_data.view_as(y_hat)).sum().item()\n",
    "            # 和y_data进行比对，计算出有几个一样的\n",
    "        \n",
    "    loss /= args[\"batch_size\"]       \n",
    "    print(\"Test:Average Loss:{:.4f}, Accuracy:{}/{} ({}%)\\n\".format(\n",
    "            loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100 * correct / len(test_loader.dataset)\n",
    "    ))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainEpoch:1 Progress:(14336/60000 (23.8933%)\tloss:0.384776\n",
      "TrainEpoch:1 Progress:(29184/60000 (48.6400%)\tloss:0.295397\n",
      "TrainEpoch:1 Progress:(44032/60000 (73.3867%)\tloss:0.200777\n",
      "TrainEpoch:1 Progress:(58880/60000 (98.1333%)\tloss:0.138194\n",
      "Test:Average Loss:0.0048, Accuracy:9642/10000 (96.42%)\n",
      "\n",
      "TrainEpoch:2 Progress:(14336/60000 (23.8933%)\tloss:0.123801\n",
      "TrainEpoch:2 Progress:(29184/60000 (48.6400%)\tloss:0.102141\n",
      "TrainEpoch:2 Progress:(44032/60000 (73.3867%)\tloss:0.086510\n",
      "TrainEpoch:2 Progress:(58880/60000 (98.1333%)\tloss:0.086306\n",
      "Test:Average Loss:0.0028, Accuracy:9770/10000 (97.7%)\n",
      "\n",
      "TrainEpoch:3 Progress:(14336/60000 (23.8933%)\tloss:0.074409\n",
      "TrainEpoch:3 Progress:(29184/60000 (48.6400%)\tloss:0.066436\n",
      "TrainEpoch:3 Progress:(44032/60000 (73.3867%)\tloss:0.043368\n",
      "TrainEpoch:3 Progress:(58880/60000 (98.1333%)\tloss:0.088545\n",
      "Test:Average Loss:0.0020, Accuracy:9825/10000 (98.25%)\n",
      "\n",
      "TrainEpoch:4 Progress:(14336/60000 (23.8933%)\tloss:0.041106\n",
      "TrainEpoch:4 Progress:(29184/60000 (48.6400%)\tloss:0.050993\n",
      "TrainEpoch:4 Progress:(44032/60000 (73.3867%)\tloss:0.049718\n",
      "TrainEpoch:4 Progress:(58880/60000 (98.1333%)\tloss:0.069497\n",
      "Test:Average Loss:0.0016, Accuracy:9854/10000 (98.54%)\n",
      "\n",
      "TrainEpoch:5 Progress:(14336/60000 (23.8933%)\tloss:0.039572\n",
      "TrainEpoch:5 Progress:(29184/60000 (48.6400%)\tloss:0.042669\n",
      "TrainEpoch:5 Progress:(44032/60000 (73.3867%)\tloss:0.040354\n",
      "TrainEpoch:5 Progress:(58880/60000 (98.1333%)\tloss:0.020715\n",
      "Test:Average Loss:0.0014, Accuracy:9867/10000 (98.67%)\n",
      "\n",
      "TrainEpoch:6 Progress:(14336/60000 (23.8933%)\tloss:0.060536\n",
      "TrainEpoch:6 Progress:(29184/60000 (48.6400%)\tloss:0.031576\n",
      "TrainEpoch:6 Progress:(44032/60000 (73.3867%)\tloss:0.022510\n",
      "TrainEpoch:6 Progress:(58880/60000 (98.1333%)\tloss:0.028348\n",
      "Test:Average Loss:0.0014, Accuracy:9877/10000 (98.77%)\n",
      "\n",
      "TrainEpoch:7 Progress:(14336/60000 (23.8933%)\tloss:0.022618\n",
      "TrainEpoch:7 Progress:(29184/60000 (48.6400%)\tloss:0.031963\n",
      "TrainEpoch:7 Progress:(44032/60000 (73.3867%)\tloss:0.030367\n",
      "TrainEpoch:7 Progress:(58880/60000 (98.1333%)\tloss:0.032257\n",
      "Test:Average Loss:0.0012, Accuracy:9891/10000 (98.91%)\n",
      "\n",
      "TrainEpoch:8 Progress:(14336/60000 (23.8933%)\tloss:0.017368\n",
      "TrainEpoch:8 Progress:(29184/60000 (48.6400%)\tloss:0.032053\n",
      "TrainEpoch:8 Progress:(44032/60000 (73.3867%)\tloss:0.043416\n",
      "TrainEpoch:8 Progress:(58880/60000 (98.1333%)\tloss:0.027547\n",
      "Test:Average Loss:0.0010, Accuracy:9905/10000 (99.05%)\n",
      "\n",
      "TrainEpoch:9 Progress:(14336/60000 (23.8933%)\tloss:0.019459\n",
      "TrainEpoch:9 Progress:(29184/60000 (48.6400%)\tloss:0.047928\n",
      "TrainEpoch:9 Progress:(44032/60000 (73.3867%)\tloss:0.022153\n",
      "TrainEpoch:9 Progress:(58880/60000 (98.1333%)\tloss:0.021219\n",
      "Test:Average Loss:0.0010, Accuracy:9919/10000 (99.19%)\n",
      "\n",
      "TrainEpoch:10 Progress:(14336/60000 (23.8933%)\tloss:0.023251\n",
      "TrainEpoch:10 Progress:(29184/60000 (48.6400%)\tloss:0.012470\n",
      "TrainEpoch:10 Progress:(44032/60000 (73.3867%)\tloss:0.026847\n",
      "TrainEpoch:10 Progress:(58880/60000 (98.1333%)\tloss:0.012363\n",
      "Test:Average Loss:0.0011, Accuracy:9907/10000 (99.07%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args[\"epoch\"] + 1):\n",
    "    train(model, args[\"device\"], optimizer, train_loader, epoch)\n",
    "    test(model, args[\"device\"], test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
